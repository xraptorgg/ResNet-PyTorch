{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms \n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device agnostic code\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dataset\n",
    "\n",
    "# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "\n",
    "# wget did not work for this kaggle notebook, hence i manually downloaded the dataset and uploaded it to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train data\n",
    "\n",
    "TRAINING_PATH = \"tiny-imagenet-200/train\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = datasets.ImageFolder(root = TRAINING_PATH, transform = transform, target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading validation data\n",
    "\n",
    "VAL_PATH = \"tiny-imagenet-200/val\"\n",
    "\n",
    "\n",
    "with open(\"tiny-imagenet-200/val/val_annotations.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "val_dict = {}\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split('\\t')\n",
    "    val_dict[parts[0]] = parts[1]\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "    \n",
    "\n",
    "val_data = datasets.ImageFolder(root = VAL_PATH, transform = transform, target_transform = None)\n",
    "\n",
    "for i in range(len(val_data)):\n",
    "    img_path, _ = val_data.imgs[i]\n",
    "    img_name = os.path.basename(img_path)\n",
    "    val_data.imgs[i] = (img_path, training_data.classes.index(val_dict[img_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shapes\n",
    "\n",
    "print(f\"Length of training data = {len(training_data)}, Shape of Image = {training_data[0][0].shape}\")\n",
    "print(f\"Length of validation data = {len(val_data)}, Shape of Image = {val_data[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label mapping file\n",
    "with open(\"tiny-imagenet-200/words.txt\", 'r') as f:\n",
    "    class_names = f.readlines()\n",
    "    \n",
    "# mapping between WordNet IDs to class names\n",
    "class_dict = {}\n",
    "for line in class_names:\n",
    "    line = line.split('\\t')\n",
    "    class_dict[line[0]] = line[1].strip()\n",
    "    \n",
    "    \n",
    "# visualise\n",
    "torch.manual_seed(1234)\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "rows, cols = 3, 3\n",
    "for i in range(rows * cols):\n",
    "    rand_idx = torch.randint(0, len(training_data), size = [1]).item()\n",
    "    image, target = training_data[rand_idx]\n",
    "    fig.add_subplot(rows, cols, i + 1)\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(class_dict[training_data.classes[target]])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "training_dataloader = DataLoader(dataset = training_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(dataset = val_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "training_images, training_targets = next(iter(training_dataloader))\n",
    "\n",
    "print(f\"Training images batch shape = {training_images.shape}\")\n",
    "print(f\"Training targets batch shape = {training_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet architecture\n",
    "# supports ResNet-34, 50, 101, 152\n",
    "# need to pass in the depth as argument\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_config = {\n",
    "            34 : [3, 4, 6, 3],\n",
    "            50 : [3, 4, 6, 3],\n",
    "            101 : [3, 4, 23, 3],\n",
    "            152 : [3, 8, 36, 3]\n",
    "        }\n",
    "        self.channel_config = {\n",
    "            34 : [64, 64, 128, 256, 512],\n",
    "            50 : [64, 256, 512, 1024, 2048],\n",
    "            101 : [64, 256, 512, 1024, 2048],\n",
    "            152 : [64, 256, 512, 1024, 2048]\n",
    "        }\n",
    "\n",
    "        self.conv_1  = conv_block(in_channels = 3, out_channels = 64, kernel_size = 7, stride = 2, padding = 3)\n",
    "        self.maxpool_1 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.conv_2 = self._make_block(num_blocks = self.block_config[config][0], num = 0, config = config)\n",
    "        self.conv_3 = self._make_block(num_blocks = self.block_config[config][1], num = 1, config = config)\n",
    "        self.conv_4 = self._make_block(num_blocks = self.block_config[config][2], num = 2, config = config)\n",
    "        self.conv_5 = self._make_block(num_blocks = self.block_config[config][3], num = 3, config = config)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features = self.channel_config[config][-1], out_features = num_classes)\n",
    "\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def _make_block(self, num_blocks, num, config):\n",
    "        block = nn.ModuleList([])\n",
    "\n",
    "        if config == 34:\n",
    "            block.append(residual_block(in_channels = self.channel_config[config][num], out_channels = self.channel_config[config][num + 1]))\n",
    "        else:\n",
    "            block.append(bottleneck_block(in_channels = self.channel_config[config][num], out_channels = self.channel_config[config][num + 1]))\n",
    "\n",
    "        for i in range(num_blocks - 1):\n",
    "            if config == 34:\n",
    "                block.append(residual_block(in_channels = self.channel_config[config][num + 1], out_channels = self.channel_config[config][num + 1]))\n",
    "            else:\n",
    "                block.append(bottleneck_block(in_channels = self.channel_config[config][num + 1], out_channels = self.channel_config[config][num + 1]))\n",
    "        return block\n",
    "\n",
    "\n",
    "    # kaiming he initialization\n",
    "    def init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(layer.weight)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "\n",
    "        for block in self.conv_2:\n",
    "            x = block(x)\n",
    "        for block in self.conv_3:\n",
    "            x = block(x)\n",
    "        for block in self.conv_4:\n",
    "            x = block(x)\n",
    "        for block in self.conv_5:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class bottleneck_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = out_channels // in_channels == 2\n",
    "        self.first = out_channels // in_channels == 4\n",
    "\n",
    "        stride = 1\n",
    "        res_channels = in_channels // 4\n",
    "\n",
    "        if self.downsample:\n",
    "            res_channels = in_channels // 2\n",
    "            stride = 2\n",
    "            self.project = conv_block(in_channels = in_channels, out_channels = out_channels, kernel_size = 1, stride = stride, padding = 0)\n",
    "\n",
    "\n",
    "        if self.first:\n",
    "            res_channels = in_channels\n",
    "            stride = 1\n",
    "            self.project = conv_block(in_channels = in_channels, out_channels = out_channels, kernel_size = 1, stride = stride, padding = 0)\n",
    "\n",
    "\n",
    "        self.conv_1 = conv_block(in_channels = in_channels, out_channels = res_channels, kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.conv_2 = conv_block(in_channels = res_channels, out_channels = res_channels, kernel_size = 3, stride = stride, padding = 1)\n",
    "        self.conv_3 = conv_block(in_channels = res_channels, out_channels = out_channels, kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.conv_1(x)\n",
    "        f = self.relu(f)\n",
    "        f = self.conv_2(f)\n",
    "        f = self.relu(f)\n",
    "        f = self.conv_3(f)\n",
    "        f = self.relu(f)\n",
    "\n",
    "        if self.downsample or self.first:\n",
    "            x = self.project(x)\n",
    "\n",
    "        h = f + x\n",
    "        return self.relu(h)\n",
    "\n",
    "\n",
    "\n",
    "class residual_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = in_channels != out_channels\n",
    "\n",
    "        stride = 1\n",
    "\n",
    "        if self.downsample:\n",
    "            stride = 2\n",
    "            self.project = conv_block(in_channels = in_channels, out_channels = out_channels, kernel_size = 1, stride = stride, padding = 0)\n",
    "\n",
    "        self.conv_1 = conv_block(in_channels = in_channels, out_channels = out_channels, kernel_size = 3, stride = stride, padding = 1)\n",
    "        self.conv_2 = conv_block(in_channels = out_channels, out_channels = out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.conv_1(x)\n",
    "        f = self.relu(f)\n",
    "        f = self.conv_2(f)\n",
    "        f = self.relu(f)\n",
    "\n",
    "        if self.downsample:\n",
    "            x = self.project(x)\n",
    "\n",
    "        h = f + x\n",
    "        return self.relu(h)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride, padding = padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.bn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and val metrics \n",
    "\n",
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "val_acc_values = []\n",
    "epoch_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "def model_train(epochs, model, train_dataloader, val_dataloader, loss_func, optimizer, scheduler):\n",
    "\n",
    "    # turn on training mode\n",
    "    model.train()\n",
    "\n",
    "    #check training device\n",
    "    print(f\"Training on {device}.\")\n",
    "\n",
    "    # loop through each epoch\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs}\\n-------------\")\n",
    "\n",
    "        # loop through each batch\n",
    "        train_loss, train_acc = 0, 0\n",
    "        total_steps = 1\n",
    "        for images, classes in train_dataloader:\n",
    "\n",
    "            #send data to device\n",
    "            images, classes = images.to(device), classes.to(device)\n",
    "\n",
    "            # computer forward pass\n",
    "            y_pred = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_func(y_pred, classes)\n",
    "            train_loss += loss\n",
    "            train_acc += accuracy_fn(y_true = classes, y_pred = y_pred.argmax(dim=1))\n",
    "\n",
    "            # update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = train_loss / total_steps\n",
    "            batch_acc = train_acc / total_steps\n",
    "\n",
    "            if total_steps % 10 == 0:\n",
    "                print(f\"Training Loss: {batch_loss:.5f} - Training Accuracy: {batch_acc:.5f}%\")\n",
    "\n",
    "            total_steps += 1\n",
    "\n",
    "        # learning rate decay\n",
    "        scheduler.step()\n",
    "\n",
    "        # performance on test set\n",
    "        # turn on inference mode\n",
    "        with torch.inference_mode():\n",
    "            # loop through each batch\n",
    "            total_val_loss, val_acc = 0, 0\n",
    "            for val_images, val_classes in val_dataloader:\n",
    "                # send data to device\n",
    "                val_images, val_classes = val_images.to(device), val_classes.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                y_val_pred = model(val_images)\n",
    "\n",
    "                # compute loss\n",
    "                val_loss = loss_func(y_val_pred, val_classes)\n",
    "                total_val_loss += val_loss\n",
    "                val_acc += accuracy_fn(y_true = val_classes, y_pred = y_val_pred.argmax(dim=1)\n",
    "                )\n",
    "            \n",
    "            total_val_loss /= len(val_dataloader)\n",
    "            val_acc /= len(val_dataloader)\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader)\n",
    "\n",
    "        print(f\"[After {epoch + 1} epochs: Train Loss: {train_loss:.5f} - Train Accuracy: {train_acc:.5f}% - Validation Loss: {total_val_loss:.5f} - Validation Accuracy: {val_acc:.5f}%]\")\n",
    "\n",
    "        \n",
    "        train_loss_values.append(train_loss.item())\n",
    "        val_loss_values.append(total_val_loss.item())\n",
    "        val_acc_values.append(val_acc)\n",
    "        epoch_count.append(epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop\n",
    "\n",
    "def model_test(model, dataloader, loss_func):\n",
    "    # turn on test mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn on inference mode\n",
    "    with torch.inference_mode():\n",
    "        # loop through each batch\n",
    "        test_loss, test_acc = 0, 0\n",
    "        for images, classes in dataloader:\n",
    "            # send data to device\n",
    "            images, classes = images.to(device), classes.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_pred = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_func(y_pred, classes)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy_fn(y_true = classes, y_pred = y_pred.argmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Loss: {test_loss:.5f} - Accuracy: {test_acc:.5f}%\")\n",
    "        return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric functions\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "resnet = ResNet(num_classes = 200, config = 50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "sgd = torch.optim.SGD(params = resnet.parameters(), lr = LEARNING_RATE, momentum = 0.9)\n",
    "\n",
    "learning_decay = torch.optim.lr_scheduler.StepLR(optimizer = sgd, step_size = 30, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "model_train(epochs = EPOCHS, model = resnet, train_dataloader = training_dataloader, val_dataloader = val_dataloader, loss_func = loss_func, optimizer = sgd, scheduler = learning_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model\n",
    "\n",
    "accuracy = model_test(model = resnet, dataloader = val_dataloader, loss_func = loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss curve\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "plt.plot(epoch_count, train_loss_values, label = \"Train loss\")\n",
    "plt.plot(epoch_count, val_loss_values, label = \"Validation loss\")\n",
    "plt.title(\"Loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy curve\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "plt.plot(epoch_count, val_acc_values, label = \"Accuracy\")\n",
    "plt.title(\"Accuracy curves\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "MODEL_NAME = \"ResNet_\" + str(accuracy).replace(\".\", \"_\") + \".pth\"\n",
    "\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving GoogLeNet to {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj = alexnet.state_dict(), f = MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
